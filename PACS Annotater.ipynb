{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e6be7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as display\n",
    "from PIL import Image\n",
    "import json\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f714007",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('image_descriptions.json') as json_data:\n",
    "    data_dict = json.load(json_data)\n",
    "    #print(data_dict)\n",
    "images = []\n",
    "for i in range(len(data_dict)):\n",
    "    images.append(data_dict[i]['image_name'])\n",
    "    \n",
    "print(images[0:10])\n",
    "print(len(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1027256",
   "metadata": {},
   "source": [
    "## Annotater\n",
    "Use the variables a and b to mark the begginning and the end of the part of the dataset you want to annotate.\n",
    "Than the program works in two steps : \n",
    "1) The first key you press is the criteria you want to modify. For example, press '1' to modify the criteria 'detail'. You can also recheck the total description by pressing 'c.\n",
    "\n",
    "2) After you can either press 1/2/3/.. to modify with the most popular annotations with this criteria or either type another description.\n",
    "\n",
    "Once the annotation has been done for this part of the dataset, you can print the dict 'version' the get back the annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a22e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a = 0\n",
    "b = 30\n",
    "test = images[a : b]\n",
    "version = []\n",
    "\n",
    "for i in range(0,100):\n",
    "    print(i)\n",
    "    path = 'Homework3-PACS-master/PACS/' + test[i]\n",
    "    display.display(Image.open(path))\n",
    "    nd = data_dict[a+i]\n",
    "    print(data_dict[a+i]['image_name'])\n",
    "    print(a+i)\n",
    "    vl = input(data_dict[a+i]['descriptions'])\n",
    "    \n",
    "    while(vl != '0'):\n",
    "        if vl == '1' : \n",
    "            vl2 = input(nd['descriptions'][0])\n",
    "            if vl2 == '1':\n",
    "                nd['descriptions'][0] = 'low level details'\n",
    "            elif vl2 == '2':\n",
    "                nd['descriptions'][0] = 'mid level details'\n",
    "            elif vl2 == '3':\n",
    "                nd['descriptions'][0] = 'high level details'\n",
    "            else:\n",
    "                nd['descriptions'][0] = vl2\n",
    "        if vl == '2' : \n",
    "            vl2 = input(nd['descriptions'][1])\n",
    "            nd['descriptions'][1] = vl2\n",
    "        if vl == '3' : \n",
    "            vl2 = input(nd['descriptions'][2])\n",
    "            if vl2 == '1':\n",
    "                nd['descriptions'][2] = 'low saturation'\n",
    "            elif vl2 == '2':\n",
    "                nd['descriptions'][2] = 'medium saturation'\n",
    "            elif vl2 == '3':\n",
    "                nd['descriptions'][2] = 'high saturation'\n",
    "            elif vl2 == '4':\n",
    "                nd['descriptions'][2] = 'medium saturation, light reflections'\n",
    "            elif vl2 == '5':\n",
    "                nd['descriptions'][2] = 'high saturation, light reflections'\n",
    "            else:\n",
    "                nd['descriptions'][2] = vl2\n",
    "        if vl == '4' : \n",
    "            vl2 = input(nd['descriptions'][3])\n",
    "            if vl2 == '1':\n",
    "                nd['descriptions'][3] = 'colorful, contrasting'\n",
    "            elif vl2 == '2':\n",
    "                nd['descriptions'][3] = 'colorful, skin shades'\n",
    "            elif vl2 == '3':\n",
    "                nd['descriptions'][3] = 'black and white'\n",
    "            elif vl2 == '4':\n",
    "                nd['descriptions'][3] = 'colorful'\n",
    "            else:\n",
    "                nd['descriptions'][3] = vl2\n",
    "        if vl == '5' : \n",
    "            vl2 = input(nd['descriptions'][4])\n",
    "            nd['descriptions'][4] = vl2\n",
    "        if vl == '6' : \n",
    "            vl2 = input(nd['descriptions'][5])\n",
    "            if vl2 == '1':\n",
    "                nd['descriptions'][5] = 'single instance'\n",
    "            elif vl2 == '2':\n",
    "                nd['descriptions'][5] = 'two instances'\n",
    "            elif vl2 == '3':\n",
    "                nd['descriptions'][5] = 'multiple instances'\n",
    "            else:\n",
    "                nd['descriptions'][5] = vl2\n",
    "        if vl == '7' : \n",
    "            vl2 = input(nd['descriptions'][6])\n",
    "            if vl2 == '1':\n",
    "                nd['descriptions'][6] = 'without text'\n",
    "            else: \n",
    "                nd['descriptions'][6] = vl2\n",
    "        if vl == '8' : \n",
    "            vl2 = input(nd['descriptions'][7])\n",
    "            if vl2 == '1':\n",
    "                nd['descriptions'][7] = 'painting strokes'\n",
    "            elif vl2 == '2':\n",
    "                nd['descriptions'][7] = 'without texture'\n",
    "            else:\n",
    "                nd['descriptions'][7] = vl2\n",
    "        if vl == '9' : \n",
    "            vl2 = input(nd['descriptions'][8])\n",
    "            if vl2 == '1':\n",
    "                nd['descriptions'][8] = 'with perspective'\n",
    "            elif vl2 == '2':\n",
    "                nd['descriptions'][8] = 'without perspective'\n",
    "            elif vl2 == '3':\n",
    "                nd['descriptions'][8] = 'realistic'\n",
    "            elif vl2 == '4':\n",
    "                nd['descriptions'][8] = 'unrealistic'\n",
    "            elif vl2 == '5':\n",
    "                nd['descriptions'][8] = 'with perspective, realistic'\n",
    "            elif vl2 == '6':\n",
    "                nd['descriptions'][8] = 'without perspective, realistic'\n",
    "            elif vl2 == '7':\n",
    "                nd['descriptions'][8] = 'with perspective, unrealistic'\n",
    "            elif vl2 == '8':\n",
    "                nd['descriptions'][8] = 'without perspective, unrealistic'\n",
    "            else:\n",
    "                nd['descriptions'][8] = vl2\n",
    "        if vl == 'del':\n",
    "            vl2 = input('quel index veux tu supprimer ?')\n",
    "            del nd['descriptions'][vl2]\n",
    "        if vl == 'c':\n",
    "            print(nd['descriptions'])\n",
    "        vl = input(\"next\")\n",
    "        print(vl)\n",
    "    version.append(nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d56aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0658fbc",
   "metadata": {},
   "source": [
    "## Pre-correction of student annotations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5025a634",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data_dict)):\n",
    "    for j in range(len(data_dict[i]['descriptions'])):\n",
    "        data_dict[i]['descriptions'][j] = data_dict[i]['descriptions'][j].split('yes ',1)[-1]\n",
    "        data_dict[i]['descriptions'][j] = data_dict[i]['descriptions'][j].split('no ',1)[-1]\n",
    "        data_dict[i]['descriptions'][j] = data_dict[i]['descriptions'][j].split('yes, ',1)[-1]\n",
    "        data_dict[i]['descriptions'][j] = data_dict[i]['descriptions'][j].split('no, ',1)[-1]\n",
    "    \n",
    "    if 'detail' not in data_dict[i]['descriptions'][0]:\n",
    "        if 'level' not in data_dict[i]['descriptions'][0]:\n",
    "            data_dict[i]['descriptions'][0] = data_dict[i]['descriptions'][0] + ' level details'\n",
    "        if 'level' in data_dict[i]['descriptions'][0]:\n",
    "            data_dict[i]['descriptions'][0] = data_dict[i]['descriptions'][0] + ' details'\n",
    "    if data_dict[i]['descriptions'][0] == 'low-level level details':\n",
    "        data_dict[i]['descriptions'][0] = 'low level details'\n",
    "        \n",
    "    if 'saturation' not in data_dict[i]['descriptions'][2]:  \n",
    "        split_strings = data_dict[i]['descriptions'][2].split(',')\n",
    "        split_strings.insert(1, ' saturation')\n",
    "        final_string = ''.join(split_strings)\n",
    "        data_dict[i]['descriptions'][2] = final_string\n",
    "    if 'sketch' in data_dict[i]['image_name']:\n",
    "        data_dict[i]['descriptions'][2] = 'medium saturation'\n",
    "    if data_dict[i]['descriptions'][1] == 'neat stroks':\n",
    "        data_dict[i]['descriptions'][1] = 'neat strokes'\n",
    "    #data_dict[i]['descriptions'][2] = data_dict[i]['descriptions'][2] + ' saturation'\n",
    "    \n",
    "    if 'sketch' in data_dict[i]['image_name']:\n",
    "        data_dict[i]['descriptions'][3] = 'black and white'\n",
    "    if data_dict[i]['descriptions'][3] == 'no':\n",
    "        data_dict[i]['descriptions'][3] = 'colorful'\n",
    "        \n",
    "    if data_dict[i]['descriptions'][4] == 'white':\n",
    "        data_dict[i]['descriptions'][4] = 'monochrome white'\n",
    "    if data_dict[i]['descriptions'][4] == 'black':\n",
    "        data_dict[i]['descriptions'][4] = 'monochrome black'\n",
    "    if data_dict[i]['descriptions'][4] == 'single color, white':\n",
    "        data_dict[i]['descriptions'][4] = 'monochrome white'\n",
    "        \n",
    "    if data_dict[i]['descriptions'][5] == 'yes':\n",
    "        data_dict[i]['descriptions'][5] = 'single instance'\n",
    "    if data_dict[i]['descriptions'][5] == 'no':\n",
    "        data_dict[i]['descriptions'][5] = 'several instance'\n",
    "        \n",
    "    if data_dict[i]['descriptions'][6] == 'yes':\n",
    "        data_dict[i]['descriptions'][6] = 'with text'\n",
    "    if data_dict[i]['descriptions'][6] == 'yes dense text':\n",
    "        data_dict[i]['descriptions'][6] = 'dense text'\n",
    "    if data_dict[i]['descriptions'][6] == 'no':\n",
    "        data_dict[i]['descriptions'][6] = 'without text'\n",
    "    if data_dict[i]['descriptions'][6] == 'text':\n",
    "        data_dict[i]['descriptions'][6] = 'without text'\n",
    "    if data_dict[i]['descriptions'][6] == 'untexted':\n",
    "        data_dict[i]['descriptions'][6] = 'without text'\n",
    "        \n",
    "    if data_dict[i]['descriptions'][7] == 'painting':\n",
    "        data_dict[i]['descriptions'][7] = 'painting strokes'\n",
    "    if data_dict[i]['descriptions'][7] == 'no':\n",
    "        data_dict[i]['descriptions'][7] = 'without texture'\n",
    "    if data_dict[i]['descriptions'][7] == 'digital drawing':\n",
    "        data_dict[i]['descriptions'][7] = 'without texture'\n",
    "    if data_dict[i]['descriptions'][7] == 'photo':\n",
    "        data_dict[i]['descriptions'][7] = 'without texture'\n",
    "    if data_dict[i]['descriptions'][7] == 'photo texture':\n",
    "        data_dict[i]['descriptions'][7] = 'without texture'\n",
    "    if data_dict[i]['descriptions'][7] == 'cartoon':\n",
    "        data_dict[i]['descriptions'][7] = 'without texture'\n",
    "    if data_dict[i]['descriptions'][7] == 'sketch':\n",
    "        data_dict[i]['descriptions'][7] = 'without texture'\n",
    "        \n",
    "    if data_dict[i]['descriptions'][8] == 'yes realistic':\n",
    "        data_dict[i]['descriptions'][8] = 'realistic'\n",
    "    if data_dict[i]['descriptions'][8] == 'no unrealistic':\n",
    "        data_dict[i]['descriptions'][8] = 'unrealistic'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7707f5a",
   "metadata": {},
   "source": [
    "## Pre-cleaning if the group didn't respect the \" 9 criteria\" format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cbd7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#solve when the '9' format is not respected\n",
    "for i in range(len(data_dict)):\n",
    "    if(len(data_dict[i]['descriptions'])) == 2:\n",
    "        data_dict[i]['descriptions'].insert(2,'colorful')\n",
    "        data_dict[i]['descriptions'].insert(3,'colorful')\n",
    "        data_dict[i]['descriptions'].insert(4,'colorful')\n",
    "        data_dict[i]['descriptions'].insert(5,'single instance')\n",
    "        data_dict[i]['descriptions'].insert(6,'without text')\n",
    "        data_dict[i]['descriptions'].insert(7,'without texture')\n",
    "        data_dict[i]['descriptions'].insert(8,'to do')\n",
    "    if(len(data_dict[i]['descriptions'])) == 3:\n",
    "        data_dict[i]['descriptions'].insert(3,'colorful')\n",
    "        data_dict[i]['descriptions'].insert(4,'colorful')\n",
    "        data_dict[i]['descriptions'].insert(5,'single instance')\n",
    "        data_dict[i]['descriptions'].insert(6,'without text')\n",
    "        data_dict[i]['descriptions'].insert(7,'without texture')\n",
    "        data_dict[i]['descriptions'].insert(8,'to do')\n",
    "    if(len(data_dict[i]['descriptions'])) == 4:\n",
    "        data_dict[i]['descriptions'].insert(4,'colorful')\n",
    "        data_dict[i]['descriptions'].insert(5,'single instance')\n",
    "        data_dict[i]['descriptions'].insert(6,'without text')\n",
    "        data_dict[i]['descriptions'].insert(7,'without texture')\n",
    "        data_dict[i]['descriptions'].insert(8,'to do')\n",
    "    if(len(data_dict[i]['descriptions'])) == 5:\n",
    "        data_dict[i]['descriptions'].insert(5,'single instance')\n",
    "        data_dict[i]['descriptions'].insert(6,'without text')\n",
    "        data_dict[i]['descriptions'].insert(7,'without texture')\n",
    "        data_dict[i]['descriptions'].insert(8,'to do')\n",
    "    if(len(data_dict[i]['descriptions'])) == 6:\n",
    "        data_dict[i]['descriptions'].insert(6,'without text')\n",
    "        data_dict[i]['descriptions'].insert(7,'without texture')\n",
    "        data_dict[i]['descriptions'].insert(8,'to do')\n",
    "    if(len(data_dict[i]['descriptions'])) == 7:\n",
    "        data_dict[i]['descriptions'].insert(7,'without texture')\n",
    "        data_dict[i]['descriptions'].insert(8,'to do')\n",
    "    if(len(data_dict[i]['descriptions'])) == 8:\n",
    "        data_dict[i]['descriptions'].insert(7,'without texture')\n",
    "    if(len(data_dict[i]['descriptions'])) == 10:\n",
    "        del data_dict[i]['descriptions'][9]\n",
    "    if(len(data_dict[i]['descriptions'])) == 11:\n",
    "        del data_dict[i]['descriptions'][9]\n",
    "        del data_dict[i]['descriptions'][9]\n",
    "    if(len(data_dict[i]['descriptions'])) == 12:\n",
    "        del data_dict[i]['descriptions'][9]\n",
    "        del data_dict[i]['descriptions'][9]\n",
    "        del data_dict[i]['descriptions'][9]\n",
    "    if(len(data_dict[i]['descriptions'])) == 13:\n",
    "        del data_dict[i]['descriptions'][9]\n",
    "        del data_dict[i]['descriptions'][9]\n",
    "        del data_dict[i]['descriptions'][9]\n",
    "        del data_dict[i]['descriptions'][9]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64eb269a",
   "metadata": {},
   "source": [
    "## Tool if the group used a tree structure to store descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bd1774c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_27652\\4141197928.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdata_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mdomain\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'PACS_domain_description/AML/Group5_287639-291018-282870_AML/datalabels'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcategory\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'PACS_domain_description/AML/Group5_287639-291018-282870_AML/datalabels/'\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mdomain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mima\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'PACS_domain_description/AML/Group5_287639-291018-282870_AML/datalabels/'\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mdomain\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcategory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "images = []\n",
    "data_dict = []\n",
    "for domain in os.listdir('PACS_domain_description/AML/Group5_287639-291018-282870_AML/datalabels'):\n",
    "    for category in os.listdir('PACS_domain_description/AML/Group5_287639-291018-282870_AML/datalabels/'+ domain):\n",
    "        for ima in os.listdir('PACS_domain_description/AML/Group5_287639-291018-282870_AML/datalabels/'+ domain + '/' + category):\n",
    "            ima = ima.split('.txt')[0]\n",
    "            images.append(domain + '/' + category + '/' + ima)\n",
    "            dic = {}\n",
    "            dic['image_name'] = domain + '/' + category + '/' + ima\n",
    "            with open('PACS_domain_description/AML/Group5_287639-291018-282870_AML/datalabels/' + domain + '/' + category + '/' + ima + '.txt' ) as f:\n",
    "                lines = f.readlines()\n",
    "                desc = []\n",
    "                for elem in lines:\n",
    "                    elem = elem.strip()\n",
    "                    desc.append(elem)\n",
    "            dic['descriptions'] = desc\n",
    "            data_dict.append(dic)\n",
    "        \n",
    "\n",
    "print(images[1:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf58ac16",
   "metadata": {},
   "source": [
    "## Visualisation\n",
    "After the modifications, you can use this code to see the number of modifications and to analyse the difference by criteria\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfea397a",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c069b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = []\n",
    "with open('PACS_domain_description/AML/Group3_290184-290265-292501_AML/image_descriptions.json') as json_data:\n",
    "    data_dict = json.load(json_data)\n",
    "\n",
    "count = 0\n",
    "count_feature = [0,0,0,0,0,0,0,0,0]\n",
    "\n",
    "print(len(data_dict))\n",
    "for i in range(len(data_dict)):\n",
    "    for j in range(len(data_dict[i]['descriptions'])):\n",
    "        if data_dict[i]['descriptions'][j] != A[i]['descriptions'][j]:\n",
    "            count = count + 1\n",
    "            count_feature[j] = count_feature[j] + 1\n",
    "            \n",
    "print(count)\n",
    "print(len(data_dict)*9)\n",
    "print(count/(len(data_dict)*9)*100)\n",
    "print(count_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d0d56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['details', 'edges', 'saturation', 'shades', 'background', 'instance', 'text', 'texture', 'perspective']\n",
    "y_pos = np.arange(len(features))\n",
    "\n",
    "plt.bar(y_pos, count_feature)\n",
    "plt.xticks(y_pos, features, rotation=90)\n",
    "\n",
    "axes = plt.axes()\n",
    "axes.set_ylim([0, len(data_dict)])\n",
    "plt.title(\"Groupe 3 AML\")\n",
    "plt.show()\n",
    "print(count_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c11a0c",
   "metadata": {},
   "source": [
    "## Tool to create the files : phrase_freq_train / word_freq_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951086cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases = []\n",
    "for i in J:\n",
    "    for d in i['descriptions']:\n",
    "        phrases.append(d)\n",
    "        \n",
    "print(len(phrases))\n",
    "\n",
    "phrase_freq = {}\n",
    "for p in phrases:\n",
    "    if p in phrase_freq.keys():\n",
    "        phrase_freq[p] = phrase_freq[p] + 1\n",
    "    else :\n",
    "        phrase_freq[p] = 1\n",
    "        \n",
    "        \n",
    "phra = []\n",
    "for i in phrase_freq.keys():\n",
    "    dic = {}\n",
    "    dic['phrase'] = i\n",
    "    dic['freq'] = phrase_freq[i]\n",
    "    phra.append(dic)\n",
    "    \n",
    "phra = sorted(phra, key = lambda i: i['freq'], reverse = True)\n",
    "\n",
    "\n",
    "f = open('phrase_freq_train.txt', 'w')\n",
    "for i in phra:\n",
    "    f.write(i['phrase'] + ' : ' + str(i['freq']) + '\\n') \n",
    "f.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b99f0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "w = []\n",
    "for d in phra:\n",
    "    for occ in range(d['freq']):\n",
    "        sentence = re.split(' ; |, |\\*|\\n',d['phrase'])\n",
    "        for word in sentence:\n",
    "            a = word.split()\n",
    "            for el in a:\n",
    "                w.append(el)\n",
    "word_freq = {}\n",
    "for word in w:\n",
    "    if word in word_freq.keys():\n",
    "        word_freq[word] = word_freq[word] + 1\n",
    "    else :\n",
    "        word_freq[word] = 1\n",
    "\n",
    "        \n",
    "wo = []\n",
    "for i in word_freq.keys():\n",
    "    dic = {}\n",
    "    dic['phrase'] = i\n",
    "    dic['freq'] = word_freq[i]\n",
    "    wo.append(dic)\n",
    "    \n",
    "wo = sorted(wo, key = lambda i: i['freq'], reverse = True)\n",
    "\n",
    "\n",
    "f = open('word_freq_train.txt', 'w')\n",
    "for i in wo:\n",
    "    f.write(i['phrase'] + ' : ' + str(i['freq']) + '\\n') \n",
    "f.close()  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
